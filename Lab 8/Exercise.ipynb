{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d2e184",
   "metadata": {},
   "source": [
    "# Text Clustering using TF-IDF and WordVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c556da70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ASPIRE\n",
      "[nltk_data]     5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\ASPIRE\n",
      "[nltk_data]     5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\ASPIRE 5\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Clustering Results:\n",
      "Document                                           Predicted Cluster\n",
      "-----------------------------------------------  -------------------\n",
      "I love playing football on the weekends                            1\n",
      "I enjoy hiking and camping in the mountains                        1\n",
      "I like to read books and watch movies                              0\n",
      "I prefer playing video games over sports                           1\n",
      "I love listening to music and going to concerts                    1\n",
      "TF-IDF Purity: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASPIRE 5\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\ASPIRE 5\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word2Vec Clustering Results:\n",
      "Document                                           Predicted Cluster\n",
      "-----------------------------------------------  -------------------\n",
      "I love playing football on the weekends                            1\n",
      "I enjoy hiking and camping in the mountains                        0\n",
      "I like to read books and watch movies                              0\n",
      "I prefer playing video games over sports                           1\n",
      "I love listening to music and going to concerts                    0\n",
      "Word2Vec Purity: 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from tabulate import tabulate\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    filtered_text = [word for word in word_tokens if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "dataset = [\"I love playing football on the weekends\",\n",
    "           \"I enjoy hiking and camping in the mountains\",\n",
    "           \"I like to read books and watch movies\",\n",
    "           \"I prefer playing video games over sports\",\n",
    "           \"I love listening to music and going to concerts\"]\n",
    "\n",
    "# Preprocess the dataset\n",
    "preprocessed_dataset = [preprocess_text(doc) for doc in dataset]\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(preprocessed_dataset)\n",
    "\n",
    "# Word2Vec Vectorization\n",
    "tokenized_dataset = [word_tokenize(preprocess_text(doc)) for doc in dataset]\n",
    "word2vec_model = Word2Vec(sentences=tokenized_dataset, vector_size=100,\n",
    "                          window=5, min_count=1, workers=4)\n",
    "\n",
    "X_word2vec = np.array([np.mean([word2vec_model.wv[word] for word in doc if word in word2vec_model.wv], axis=0)\n",
    "                       for doc in tokenized_dataset])\n",
    "\n",
    "# Clustering\n",
    "k = 2 # Define the number of clusters\n",
    "km = KMeans(n_clusters=k)\n",
    "km.fit(X_tfidf)\n",
    "# Predict the clusters for each document\n",
    "y_pred_tfidf = km.predict(X_tfidf)\n",
    "\n",
    "# Tabulate the document and predicted cluster for TF-IDF\n",
    "table_data_tfidf = [[\"Document\", \"Predicted Cluster\"]]\n",
    "table_data_tfidf.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred_tfidf)])\n",
    "print(\"TF-IDF Clustering Results:\")\n",
    "print(tabulate(table_data_tfidf, headers=\"firstrow\"))\n",
    "\n",
    "# Calculate purity for TF-IDF\n",
    "total_samples_tfidf = len(y_pred_tfidf)\n",
    "cluster_label_counts_tfidf = [Counter(y_pred_tfidf)]\n",
    "purity_tfidf = sum(max(cluster.values()) for cluster in cluster_label_counts_tfidf) / total_samples_tfidf\n",
    "print(\"TF-IDF Purity:\", purity_tfidf)\n",
    "\n",
    "# Clustering for Word2Vec\n",
    "km.fit(X_word2vec)\n",
    "# Predict the clusters for each document\n",
    "y_pred_word2vec = km.predict(X_word2vec)\n",
    "\n",
    "# Tabulate the document and predicted cluster for Word2Vec\n",
    "table_data_word2vec = [[\"Document\", \"Predicted Cluster\"]]\n",
    "table_data_word2vec.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred_word2vec)])\n",
    "print(\"\\nWord2Vec Clustering Results:\")\n",
    "print(tabulate(table_data_word2vec, headers=\"firstrow\"))\n",
    "\n",
    "# Calculate purity for Word2Vec\n",
    "total_samples_word2vec = len(y_pred_word2vec)\n",
    "cluster_label_counts_word2vec = [Counter(y_pred_word2vec)]\n",
    "purity_word2vec = sum(max(cluster.values()) for cluster in cluster_label_counts_word2vec) / total_samples_word2vec\n",
    "print(\"Word2Vec Purity:\", purity_word2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee64be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
